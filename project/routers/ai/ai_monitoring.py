"""
ä¼ä¸šçº§AIç›‘æ§è·¯ç”±
æä¾›å®æ—¶ç›‘æ§ã€æ€§èƒ½åˆ†æã€å‘Šè­¦ç­‰åŠŸèƒ½
"""

import asyncio
import time
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from collections import defaultdict

from fastapi import APIRouter, Depends, HTTPException, status, Query, WebSocket, WebSocketDisconnect
from fastapi.responses import StreamingResponse, JSONResponse
from sqlalchemy.orm import Session
from pydantic import BaseModel, Field

# é¡¹ç›®ä¾èµ–
from project.database import get_db
from project.utils import get_current_user_id
from project.models import User, AIConversation, AIConversationMessage

# AIæä¾›è€…é›†æˆ
from project.ai_providers.provider_manager import AIProviderManager

# ä¼ä¸šçº§æ—¥å¿—å’Œç›‘æ§
try:
    from logs.ai_providers.ai_logger import get_ai_logger
    from logs.ai_providers.cache_manager import get_cache_stats
    from logs.ai_providers.connection_manager import get_connection_stats
    from logs.metrics.health_20250830 import get_health_metrics
    logger = get_ai_logger("ai_monitoring")
    ENTERPRISE_MONITORING = True
except ImportError:
    import logging
    logger = logging.getLogger("ai_monitoring")
    ENTERPRISE_MONITORING = False


# === ç›‘æ§æ•°æ®æ¨¡å‹ ===

class RealTimeMetrics(BaseModel):
    """å®æ—¶æŒ‡æ ‡æ¨¡å‹"""
    timestamp: datetime
    requests_per_second: float
    average_response_time: float
    error_rate: float
    active_connections: int
    memory_usage_mb: float
    cpu_usage_percent: float
    cache_hit_rate: float


class ProviderPerformance(BaseModel):
    """æä¾›è€…æ€§èƒ½æŒ‡æ ‡"""
    provider_name: str
    model: str
    total_requests: int
    successful_requests: int
    failed_requests: int
    average_response_time: float
    p95_response_time: float
    p99_response_time: float
    tokens_per_second: float
    cost_estimate: float


class AlertRule(BaseModel):
    """å‘Šè­¦è§„åˆ™"""
    id: str
    name: str
    metric: str
    operator: str  # gt, lt, eq, ne
    threshold: float
    duration_minutes: int
    enabled: bool
    last_triggered: Optional[datetime] = None


class SystemAlert(BaseModel):
    """ç³»ç»Ÿå‘Šè­¦"""
    id: str
    rule_id: str
    level: str  # info, warning, error, critical
    message: str
    metric_value: float
    threshold: float
    triggered_at: datetime
    resolved_at: Optional[datetime] = None


# === WebSocketè¿æ¥ç®¡ç† ===

class ConnectionManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.user_connections: Dict[int, List[WebSocket]] = defaultdict(list)
    
    async def connect(self, websocket: WebSocket, user_id: int):
        """å»ºç«‹è¿æ¥"""
        await websocket.accept()
        self.active_connections.append(websocket)
        self.user_connections[user_id].append(websocket)
        logger.info(f"WebSocket connected for user {user_id}")
    
    def disconnect(self, websocket: WebSocket, user_id: int):
        """æ–­å¼€è¿æ¥"""
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        if websocket in self.user_connections[user_id]:
            self.user_connections[user_id].remove(websocket)
        logger.info(f"WebSocket disconnected for user {user_id}")
    
    async def send_personal_message(self, message: str, user_id: int):
        """å‘é€ä¸ªäººæ¶ˆæ¯"""
        for connection in self.user_connections[user_id]:
            try:
                await connection.send_text(message)
            except:
                # è¿æ¥å·²æ–­å¼€ï¼Œç§»é™¤
                self.disconnect(connection, user_id)
    
    async def broadcast(self, message: str):
        """å¹¿æ’­æ¶ˆæ¯"""
        dead_connections = []
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except:
                dead_connections.append(connection)
        
        # æ¸…ç†æ­»è¿æ¥
        for connection in dead_connections:
            if connection in self.active_connections:
                self.active_connections.remove(connection)


# === å…¨å±€å®ä¾‹ ===
connection_manager = ConnectionManager()


# === ç›‘æ§æ•°æ®æ”¶é›† ===

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.provider_manager = None
        self._metrics_history = []
        self._alert_rules = []
        self._active_alerts = []
    
    async def initialize(self):
        """åˆå§‹åŒ–"""
        self.provider_manager = AIProviderManager()
        await self.provider_manager.initialize()
    
    async def collect_real_time_metrics(self) -> RealTimeMetrics:
        """æ”¶é›†å®æ—¶æŒ‡æ ‡"""
        try:
            current_time = datetime.now()
            
            # åŸºç¡€æŒ‡æ ‡
            if ENTERPRISE_MONITORING:
                health_data = get_health_metrics()
                connection_stats = get_connection_stats()
                cache_stats = get_cache_stats()
                
                metrics = RealTimeMetrics(
                    timestamp=current_time,
                    requests_per_second=health_data.get("requests_per_second", 0.0),
                    average_response_time=health_data.get("avg_response_time", 0.0),
                    error_rate=health_data.get("error_rate", 0.0),
                    active_connections=connection_stats.get("active_connections", 0),
                    memory_usage_mb=health_data.get("memory_usage_mb", 0.0),
                    cpu_usage_percent=health_data.get("cpu_usage_percent", 0.0),
                    cache_hit_rate=cache_stats.get("hit_rate", 0.0)
                )
            else:
                # ç®€åŒ–æŒ‡æ ‡
                metrics = RealTimeMetrics(
                    timestamp=current_time,
                    requests_per_second=0.0,
                    average_response_time=0.0,
                    error_rate=0.0,
                    active_connections=len(connection_manager.active_connections),
                    memory_usage_mb=0.0,
                    cpu_usage_percent=0.0,
                    cache_hit_rate=0.0
                )
            
            # ä¿å­˜å†å²è®°å½•
            self._metrics_history.append(metrics)
            if len(self._metrics_history) > 1000:  # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•
                self._metrics_history.pop(0)
            
            return metrics
            
        except Exception as e:
            logger.error(f"Failed to collect metrics: {e}")
            raise
    
    async def collect_provider_performance(self, hours: int = 1) -> List[ProviderPerformance]:
        """æ”¶é›†æä¾›è€…æ€§èƒ½æ•°æ®"""
        try:
            if not self.provider_manager:
                await self.initialize()
            
            performance_data = []
            
            # è·å–æ‰€æœ‰æä¾›è€…çš„æ€§èƒ½æ•°æ®
            for provider_name in self.provider_manager.get_all_provider_names():
                try:
                    stats = await self.provider_manager.get_provider_stats(
                        provider_name, 
                        datetime.now() - timedelta(hours=hours),
                        datetime.now()
                    )
                    
                    provider = self.provider_manager.get_llm_provider(provider_name)
                    
                    performance = ProviderPerformance(
                        provider_name=provider_name,
                        model=getattr(provider, 'model', 'unknown'),
                        total_requests=stats.get("total_requests", 0),
                        successful_requests=stats.get("successful_requests", 0),
                        failed_requests=stats.get("failed_requests", 0),
                        average_response_time=stats.get("avg_response_time", 0.0),
                        p95_response_time=stats.get("p95_response_time", 0.0),
                        p99_response_time=stats.get("p99_response_time", 0.0),
                        tokens_per_second=stats.get("tokens_per_second", 0.0),
                        cost_estimate=stats.get("cost_estimate", 0.0)
                    )
                    
                    performance_data.append(performance)
                    
                except Exception as e:
                    logger.warning(f"Failed to get performance data for {provider_name}: {e}")
            
            return performance_data
            
        except Exception as e:
            logger.error(f"Failed to collect provider performance: {e}")
            return []
    
    async def check_alerts(self, current_metrics: RealTimeMetrics):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        try:
            for rule in self._alert_rules:
                if not rule.enabled:
                    continue
                
                # è·å–æŒ‡æ ‡å€¼
                metric_value = getattr(current_metrics, rule.metric, None)
                if metric_value is None:
                    continue
                
                # æ£€æŸ¥é˜ˆå€¼
                should_alert = False
                if rule.operator == "gt" and metric_value > rule.threshold:
                    should_alert = True
                elif rule.operator == "lt" and metric_value < rule.threshold:
                    should_alert = True
                elif rule.operator == "eq" and metric_value == rule.threshold:
                    should_alert = True
                elif rule.operator == "ne" and metric_value != rule.threshold:
                    should_alert = True
                
                if should_alert:
                    # åˆ›å»ºå‘Šè­¦
                    alert = SystemAlert(
                        id=f"alert_{int(time.time())}_{rule.id}",
                        rule_id=rule.id,
                        level="warning" if metric_value > rule.threshold * 1.5 else "error",
                        message=f"{rule.name}: {rule.metric} = {metric_value} (threshold: {rule.threshold})",
                        metric_value=metric_value,
                        threshold=rule.threshold,
                        triggered_at=datetime.now()
                    )
                    
                    self._active_alerts.append(alert)
                    rule.last_triggered = datetime.now()
                    
                    # å‘é€å‘Šè­¦é€šçŸ¥
                    await self._send_alert_notification(alert)
            
        except Exception as e:
            logger.error(f"Failed to check alerts: {e}")
    
    async def _send_alert_notification(self, alert: SystemAlert):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        alert_message = json.dumps({
            "type": "alert",
            "data": alert.dict()
        })
        
        await connection_manager.broadcast(alert_message)


# === å…¨å±€æ”¶é›†å™¨å®ä¾‹ ===
metrics_collector = MetricsCollector()


# === æƒé™éªŒè¯ ===

async def verify_monitoring_permission(
    user_id: int = Depends(get_current_user_id),
    db: Session = Depends(get_db)
) -> bool:
    """éªŒè¯ç›‘æ§æƒé™"""
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ç”¨æˆ·æœªæ‰¾åˆ°"
        )
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç›‘æ§æƒé™ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒé™å­—æ®µè°ƒæ•´ï¼‰
    if not getattr(user, 'can_monitor', False) and not getattr(user, 'is_admin', False):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="éœ€è¦ç›‘æ§æƒé™"
        )
    
    return True


# === è·¯ç”±å®šä¹‰ ===

router = APIRouter(
    prefix="/ai/monitoring",
    tags=["AIç›‘æ§ç»Ÿè®¡"],
    dependencies=[Depends(verify_monitoring_permission)],
    responses={
        403: {"description": "ç¦æ­¢è®¿é—® - éœ€è¦ç›‘æ§æƒé™"},
        404: {"description": "èµ„æºæœªæ‰¾åˆ°"}
    }
)


@router.get("/metrics/real-time", response_model=RealTimeMetrics, summary="è·å–å®æ—¶æŒ‡æ ‡")
async def get_real_time_metrics():
    """è·å–å®æ—¶ç³»ç»ŸæŒ‡æ ‡"""
    try:
        if metrics_collector.provider_manager is None:
            await metrics_collector.initialize()
        
        metrics = await metrics_collector.collect_real_time_metrics()
        return metrics
        
    except Exception as e:
        logger.error(f"Failed to get real-time metrics: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å®æ—¶æŒ‡æ ‡å¤±è´¥: {str(e)}"
        )


@router.get("/metrics/history", summary="è·å–å†å²æŒ‡æ ‡")
async def get_metrics_history(
    hours: int = Query(default=24, ge=1, le=168),
    resolution: str = Query(default="5m", regex="^(1m|5m|15m|1h)$")
):
    """è·å–å†å²æŒ‡æ ‡æ•°æ®"""
    try:
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        # ä»å†å²è®°å½•ä¸­ç­›é€‰æ•°æ®
        filtered_metrics = [
            m for m in metrics_collector._metrics_history 
            if start_time <= m.timestamp <= end_time
        ]
        
        # æ ¹æ®åˆ†è¾¨ç‡èšåˆæ•°æ®
        if resolution == "1m":
            aggregated = filtered_metrics  # ä¸èšåˆ
        else:
            # ç®€åŒ–èšåˆé€»è¾‘
            aggregated = filtered_metrics[::5] if resolution == "5m" else filtered_metrics[::15]
        
        return {
            "metrics": [m.dict() for m in aggregated],
            "time_range": {
                "start": start_time.isoformat(),
                "end": end_time.isoformat()
            },
            "resolution": resolution,
            "total_points": len(aggregated)
        }
        
    except Exception as e:
        logger.error(f"Failed to get metrics history: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æŒ‡æ ‡å†å²å¤±è´¥: {str(e)}"
        )


@router.get("/providers/performance", response_model=List[ProviderPerformance], summary="è·å–æä¾›è€…æ€§èƒ½")
async def get_provider_performance(
    hours: int = Query(default=1, ge=1, le=168)
):
    """è·å–æä¾›è€…æ€§èƒ½æ•°æ®"""
    try:
        performance_data = await metrics_collector.collect_provider_performance(hours)
        return performance_data
        
    except Exception as e:
        logger.error(f"Failed to get provider performance: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–AIæä¾›è€…æ€§èƒ½æ•°æ®å¤±è´¥: {str(e)}"
        )


@router.get("/alerts/rules", response_model=List[AlertRule], summary="è·å–å‘Šè­¦è§„åˆ™")
async def get_alert_rules():
    """è·å–å‘Šè­¦è§„åˆ™åˆ—è¡¨"""
    return metrics_collector._alert_rules


@router.post("/alerts/rules", response_model=AlertRule, summary="åˆ›å»ºå‘Šè­¦è§„åˆ™")
async def create_alert_rule(rule: AlertRule):
    """åˆ›å»ºå‘Šè­¦è§„åˆ™"""
    try:
        # éªŒè¯æŒ‡æ ‡åç§°
        valid_metrics = ["requests_per_second", "average_response_time", "error_rate", 
                        "memory_usage_mb", "cpu_usage_percent", "cache_hit_rate"]
        if rule.metric not in valid_metrics:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Invalid metric. Valid metrics: {valid_metrics}"
            )
        
        # æ·»åŠ è§„åˆ™
        metrics_collector._alert_rules.append(rule)
        
        logger.info(f"Created alert rule: {rule.name}")
        return rule
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to create alert rule: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºå‘Šè­¦è§„åˆ™å¤±è´¥: {str(e)}"
        )


@router.get("/alerts/active", response_model=List[SystemAlert], summary="è·å–æ´»è·ƒå‘Šè­¦")
async def get_active_alerts():
    """è·å–æ´»è·ƒå‘Šè­¦åˆ—è¡¨"""
    # è¿”å›æœªè§£å†³çš„å‘Šè­¦
    active_alerts = [alert for alert in metrics_collector._active_alerts if alert.resolved_at is None]
    return active_alerts


@router.post("/alerts/{alert_id}/resolve", summary="è§£å†³å‘Šè­¦")
async def resolve_alert(alert_id: str):
    """è§£å†³å‘Šè­¦"""
    try:
        for alert in metrics_collector._active_alerts:
            if alert.id == alert_id:
                alert.resolved_at = datetime.now()
                logger.info(f"Resolved alert: {alert_id}")
                return {"message": "å‘Šè­¦è§£å†³æˆåŠŸ"}
        
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å‘Šè­¦æœªæ‰¾åˆ°"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to resolve alert: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è§£å†³å‘Šè­¦å¤±è´¥: {str(e)}"
        )


@router.get("/dashboard/summary", summary="è·å–ä»ªè¡¨æ¿æ‘˜è¦")
async def get_dashboard_summary():
    """è·å–ç›‘æ§ä»ªè¡¨æ¿æ‘˜è¦æ•°æ®"""
    try:
        # è·å–æœ€æ–°æŒ‡æ ‡
        current_metrics = await metrics_collector.collect_real_time_metrics()
        
        # è·å–æä¾›è€…æ€§èƒ½
        provider_performance = await metrics_collector.collect_provider_performance(1)
        
        # ç»Ÿè®¡æ´»è·ƒå‘Šè­¦
        active_alerts_count = len([
            alert for alert in metrics_collector._active_alerts 
            if alert.resolved_at is None
        ])
        
        # è®¡ç®—æ€»ä½“å¥åº·åˆ†æ•°
        health_score = 100.0
        if current_metrics.error_rate > 0.05:  # é”™è¯¯ç‡ > 5%
            health_score -= 20
        if current_metrics.average_response_time > 2000:  # å“åº”æ—¶é—´ > 2s
            health_score -= 15
        if current_metrics.cpu_usage_percent > 80:  # CPU > 80%
            health_score -= 10
        if current_metrics.memory_usage_mb > 8000:  # å†…å­˜ > 8GB
            health_score -= 10
        
        return {
            "timestamp": datetime.now().isoformat(),
            "health_score": max(0, health_score),
            "current_metrics": current_metrics.dict(),
            "provider_count": len(provider_performance),
            "active_alerts": active_alerts_count,
            "total_providers": len(provider_performance),
            "healthy_providers": len([p for p in provider_performance if p.failed_requests == 0]),
            "enterprise_features_enabled": ENTERPRISE_MONITORING
        }
        
    except Exception as e:
        logger.error(f"Failed to get dashboard summary: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»ªè¡¨æ¿æ‘˜è¦å¤±è´¥: {str(e)}"
        )


@router.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: int):
    """WebSocketç«¯ç‚¹ç”¨äºå®æ—¶ç›‘æ§æ•°æ®æ¨é€"""
    await connection_manager.connect(websocket, user_id)
    
    try:
        # å¯åŠ¨æŒ‡æ ‡æ¨é€ä»»åŠ¡
        async def send_metrics():
            while True:
                try:
                    metrics = await metrics_collector.collect_real_time_metrics()
                    await metrics_collector.check_alerts(metrics)
                    
                    message = json.dumps({
                        "type": "metrics",
                        "data": metrics.dict()
                    })
                    
                    await connection_manager.send_personal_message(message, user_id)
                    await asyncio.sleep(5)  # æ¯5ç§’æ¨é€ä¸€æ¬¡
                    
                except Exception as e:
                    logger.error(f"Error sending metrics: {e}")
                    break
        
        # å¯åŠ¨æ¨é€ä»»åŠ¡
        metrics_task = asyncio.create_task(send_metrics())
        
        # ä¿æŒè¿æ¥
        while True:
            try:
                data = await websocket.receive_text()
                # å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯ï¼ˆå¦‚è®¢é˜…ç‰¹å®šæŒ‡æ ‡ç­‰ï¼‰
                logger.info(f"Received WebSocket message from user {user_id}: {data}")
            except WebSocketDisconnect:
                break
            
    except Exception as e:
        logger.error(f"WebSocket error for user {user_id}: {e}")
    finally:
        connection_manager.disconnect(websocket, user_id)
        if 'metrics_task' in locals():
            metrics_task.cancel()


@router.get("/export/metrics", summary="å¯¼å‡ºç›‘æ§æŒ‡æ ‡")
async def export_metrics(
    format: str = Query(default="json", regex="^(json|csv)$"),
    hours: int = Query(default=24, ge=1, le=168)
):
    """å¯¼å‡ºç›‘æ§æŒ‡æ ‡æ•°æ®"""
    try:
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        # è·å–å†å²æ•°æ®
        filtered_metrics = [
            m for m in metrics_collector._metrics_history 
            if start_time <= m.timestamp <= end_time
        ]
        
        if format == "json":
            return {
                "metrics": [m.dict() for m in filtered_metrics],
                "exported_at": datetime.now().isoformat(),
                "time_range": {
                    "start": start_time.isoformat(),
                    "end": end_time.isoformat()
                }
            }
        else:  # CSV
            # ç”ŸæˆCSVæ•°æ®
            csv_lines = ["timestamp,requests_per_second,average_response_time,error_rate,active_connections,memory_usage_mb,cpu_usage_percent,cache_hit_rate"]
            
            for m in filtered_metrics:
                csv_lines.append(
                    f"{m.timestamp.isoformat()},{m.requests_per_second},{m.average_response_time},"
                    f"{m.error_rate},{m.active_connections},{m.memory_usage_mb},"
                    f"{m.cpu_usage_percent},{m.cache_hit_rate}"
                )
            
            csv_content = "\n".join(csv_lines)
            
            return StreamingResponse(
                iter([csv_content]),
                media_type="text/csv",
                headers={"Content-Disposition": f"attachment; filename=ai_metrics_{int(time.time())}.csv"}
            )
        
    except Exception as e:
        logger.error(f"Failed to export metrics: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯¼å‡ºæŒ‡æ ‡å¤±è´¥: {str(e)}"
        )

# æ¨¡å—åŠ è½½æ—¥å¿—
logger.info("ğŸ“Š AI Monitoring Module - AIç›‘æ§æ¨¡å—å·²åŠ è½½")
