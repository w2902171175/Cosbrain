# project/import_data.py
import pandas as pd
import numpy as np
import os, httpx, json, asyncio, re
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import text
from datetime import datetime, timedelta
from database import SessionLocal, engine, init_db, Base
from models import User, Project

# --- 1. é…ç½®å¸¸é‡ ---
# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œç„¶åæ„å»ºæ­£ç¡®çš„æ•°æ®æ–‡ä»¶è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
STUDENTS_CSV_PATH = os.path.join(SCRIPT_DIR, 'data', 'students.csv')
PROJECTS_CSV_PATH = os.path.join(SCRIPT_DIR, 'data', 'projects.csv')

# é…ç½®å¸¸é‡
DEFAULT_EMBEDDING_DIM = 1024
DEFAULT_SKILL_LEVEL = "åˆçª¥é—¨å¾„"
VALID_SKILL_LEVELS = ["åˆçª¥é—¨å¾„", "ç™»å ‚å…¥å®¤", "èä¼šè´¯é€š", "ç‚‰ç«çº¯é’"]


# --- 3. é€šç”¨å·¥å…·å‡½æ•° ---
def get_string_value(val):
    """ç»Ÿä¸€çš„å­—ç¬¦ä¸²å€¼å¤„ç†å‡½æ•°"""
    if pd.isna(val) or val is None or (isinstance(val, str) and val.strip() == ""):
        return ''
    if isinstance(val, (datetime, pd.Timestamp)):
        return val.strftime("%Y-%m-%d")
    if isinstance(val, (int, float)):
        return f"{int(val)}å°æ—¶" if val == int(val) else f"{val}å°æ—¶"
    return str(val).strip()


def parse_json_field(raw_data, field_name="field", default_value=None):
    """ç»Ÿä¸€çš„JSONå­—æ®µè§£æå‡½æ•°"""
    if default_value is None:
        default_value = []
        
    if pd.isna(raw_data) or not str(raw_data).strip():
        return default_value
        
    try:
        return json.loads(str(raw_data))
    except json.JSONDecodeError:
        print(f"Warning: Failed to parse JSON for {field_name}, treating as string")
        return str(raw_data).strip()
    except Exception as e:
        print(f"Error processing {field_name}: {e}")
        return default_value


def process_skills_data(raw_data, record_id=None):
    """ç»Ÿä¸€çš„æŠ€èƒ½æ•°æ®å¤„ç†å‡½æ•°"""
    processed_skills = []
    
    if pd.isna(raw_data) or not str(raw_data).strip():
        return processed_skills
        
    try:
        parsed_content = json.loads(str(raw_data))
        
        if isinstance(parsed_content, list):
            for item in parsed_content:
                if isinstance(item, dict) and "name" in item:
                    level = item.get("level", DEFAULT_SKILL_LEVEL)
                    processed_skills.append({
                        "name": item["name"],
                        "level": level if level in VALID_SKILL_LEVELS else DEFAULT_SKILL_LEVEL
                    })
                elif isinstance(item, str) and item.strip():
                    processed_skills.append({
                        "name": item.strip(), 
                        "level": DEFAULT_SKILL_LEVEL
                    })
        elif isinstance(parsed_content, dict) and "name" in parsed_content:
            level = parsed_content.get("level", DEFAULT_SKILL_LEVEL)
            processed_skills.append({
                "name": parsed_content["name"],
                "level": level if level in VALID_SKILL_LEVELS else DEFAULT_SKILL_LEVEL
            })
        else:
            # å¦‚æœè§£æçš„å†…å®¹ä¸æ˜¯é¢„æœŸæ ¼å¼ï¼ŒæŒ‰é€—å·åˆ†å‰²å¤„ç†
            skill_names = [s.strip() for s in str(raw_data).split(',') if s.strip()]
            processed_skills.extend([
                {"name": name, "level": DEFAULT_SKILL_LEVEL} for name in skill_names
            ])
    except json.JSONDecodeError:
        # JSONè§£æå¤±è´¥ï¼ŒæŒ‰é€—å·åˆ†å‰²å¤„ç†
        skill_names = [s.strip() for s in str(raw_data).split(',') if s.strip()]
        processed_skills.extend([
            {"name": name, "level": DEFAULT_SKILL_LEVEL} for name in skill_names
        ])
    except Exception as e:
        print(f"Warning: Error processing skills for record {record_id}: {e}")
        processed_skills = []
        
    return processed_skills


def process_roles_data(raw_data, record_id=None):
    """ç»Ÿä¸€çš„è§’è‰²æ•°æ®å¤„ç†å‡½æ•°"""
    processed_roles = []
    
    if pd.isna(raw_data) or not str(raw_data).strip():
        return processed_roles
        
    try:
        parsed_content = json.loads(str(raw_data))
        if isinstance(parsed_content, list) and all(isinstance(r, str) for r in parsed_content):
            processed_roles.extend([r.strip() for r in parsed_content if r.strip()])
        elif isinstance(parsed_content, str) and parsed_content.strip():
            processed_roles.append(parsed_content.strip())
        else:
            role_names = [r.strip() for r in str(raw_data).split(',') if r.strip()]
            processed_roles.extend(role_names)
    except json.JSONDecodeError:
        role_names = [r.strip() for r in str(raw_data).split(',') if r.strip()]
        processed_roles.extend(role_names)
    except Exception as e:
        print(f"Warning: Error processing roles for record {record_id}: {e}")
        processed_roles = []
        
    return processed_roles
# --- 4. æ•°æ®é¢„å¤„ç†å‡½æ•° ---
def preprocess_student_data(df: pd.DataFrame) -> pd.DataFrame:
    """ä¸ºå­¦ç”Ÿæ•°æ®ç”Ÿæˆ combined_textï¼Œå¹¶å¤„ç† skills å­—æ®µå’Œç¡®ä¿ username å”¯ä¸€ã€‚"""
    
    # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„åˆ—å­˜åœ¨
    required_cols = ['username', 'email', 'phone_number', 'school', 'password_hash',
                     'major', 'skills', 'interests', 'bio', 'awards_competitions',
                     'academic_achievements', 'soft_skills', 'portfolio_link',
                     'preferred_role', 'availability', 'location']
    
    for col_name in required_cols:
        if col_name not in df.columns:
            df[col_name] = np.nan

    # æ‰¹é‡å¤„ç†æ•°æ®ï¼Œé¿å…ä½¿ç”¨iterrows
    df_copy = df.copy()
    
    # æ‰¹é‡ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
    user_ids = df_copy['id'].astype(int)
    
    # å¤„ç†é‚®ç®±å­—æ®µ
    mask_email = df_copy['email'].isna() | (df_copy['email'].astype(str).str.strip() == '')
    df_copy.loc[mask_email, 'email'] = user_ids[mask_email].apply(lambda x: f"user{x:04d}@example.com")
    
    # å¤„ç†æ‰‹æœºå·å­—æ®µ
    mask_phone = df_copy['phone_number'].isna() | (df_copy['phone_number'].astype(str).str.strip() == '')
    df_copy.loc[mask_phone, 'phone_number'] = user_ids[mask_phone].apply(lambda x: f"139{x:08d}")
    
    # å¤„ç†å­¦æ ¡å­—æ®µ
    mask_school = df_copy['school'].isna() | (df_copy['school'].astype(str).str.strip() == '')
    df_copy.loc[mask_school, 'school'] = user_ids[mask_school].apply(lambda x: f"ç¤ºä¾‹å¤§å­¦_{x}")
    
    # å¤„ç†å¯†ç å“ˆå¸Œå­—æ®µ
    mask_password = df_copy['password_hash'].isna() | (df_copy['password_hash'].astype(str).str.strip() == '')
    df_copy.loc[mask_password, 'password_hash'] = user_ids[mask_password].apply(lambda x: f"hash_{x}_placeholder")
    
    # å¤„ç†ç”¨æˆ·åå­—æ®µï¼Œç¡®ä¿å”¯ä¸€æ€§
    original_usernames = df_copy['username'].fillna("æ–°ç”¨æˆ·").astype(str)
    df_copy['username'] = [f"{name.strip()}_{uid}" for name, uid in zip(original_usernames, user_ids)]
    
    # å¤„ç†æŠ€èƒ½å­—æ®µå’Œç”Ÿæˆcombined_text
    processed_data = []
    for index, row in df_copy.iterrows():
        user_id = int(row['id'])
        
        # å¤„ç†æŠ€èƒ½æ•°æ®
        processed_skills = process_skills_data(row['skills'], user_id)
        df_copy.at[index, 'skills'] = json.dumps(processed_skills, ensure_ascii=False)
        
        # ç”Ÿæˆcombined_text
        skills_text = ", ".join([s.get("name", "") for s in processed_skills if isinstance(s, dict) and s.get("name")])
        
        combined_parts = [
            get_string_value(row.get('major')),
            skills_text,
            get_string_value(row.get('interests')),
            get_string_value(row.get('bio')),
            get_string_value(row.get('awards_competitions')),
            get_string_value(row.get('academic_achievements')),
            get_string_value(row.get('soft_skills')),
            get_string_value(row.get('portfolio_link')),
            get_string_value(row.get('preferred_role')),
            get_string_value(row.get('availability')),
            get_string_value(row.get('location'))
        ]
        
        df_copy.at[index, 'combined_text'] = ". ".join(filter(None, combined_parts)).strip()
        if not df_copy.at[index, 'combined_text']:
            df_copy.at[index, 'combined_text'] = ""

    return df_copy


def preprocess_project_data(df: pd.DataFrame) -> pd.DataFrame:
    """ä¸ºé¡¹ç›®æ•°æ®ç”Ÿæˆ combined_textï¼Œå¹¶å¤„ç† required_skills/roles å­—æ®µã€‚"""
    
    # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„åˆ—å­˜åœ¨
    required_cols = ['creator_id', 'description', 'keywords', 'project_type',
                     'expected_deliverables', 'contact_person_info', 'learning_outcomes',
                     'team_size_preference', 'project_status', 'required_skills',
                     'required_roles', 'start_date', 'end_date', 'estimated_weekly_hours', 'location']
    
    for col_name in required_cols:
        if col_name not in df.columns:
            df[col_name] = np.nan

    # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸæ•°æ®
    df_copy = df.copy()
    
    # æ‰¹é‡å¤„ç†æ¯ä¸€è¡Œ
    for index, row in df_copy.iterrows():
        project_id = int(row['id'])
        
        # å¤„ç†å¿…éœ€æŠ€èƒ½æ•°æ®
        processed_skills = process_skills_data(row['required_skills'], project_id)
        df_copy.at[index, 'required_skills'] = json.dumps(processed_skills, ensure_ascii=False)
        
        # å¤„ç†å¿…éœ€è§’è‰²æ•°æ®
        processed_roles = process_roles_data(row['required_roles'], project_id)
        df_copy.at[index, 'required_roles'] = json.dumps(processed_roles, ensure_ascii=False)
        
        # ç”Ÿæˆcombined_text
        skills_text = ", ".join([s.get("name", "") for s in processed_skills if isinstance(s, dict) and s.get("name")])
        roles_text = ", ".join([r for r in processed_roles if isinstance(r, str) and r.strip()])
        
        combined_parts = [
            get_string_value(row.get('title')),
            get_string_value(row.get('description')),
            skills_text,
            roles_text,
            get_string_value(row.get('keywords')),
            get_string_value(row.get('project_type')),
            get_string_value(row.get('expected_deliverables')),
            get_string_value(row.get('contact_person_info')),
            get_string_value(row.get('learning_outcomes')),
            get_string_value(row.get('team_size_preference')),
            get_string_value(row.get('project_status')),
            get_string_value(row.get('start_date')),
            get_string_value(row.get('end_date')),
            get_string_value(row.get('estimated_weekly_hours')),
            get_string_value(row.get('location'))
        ]
        
        df_copy.at[index, 'combined_text'] = ". ".join(filter(None, combined_parts)).strip()
        if not df_copy.at[index, 'combined_text']:
            df_copy.at[index, 'combined_text'] = ""

    return df_copy


# --- 5. æ•°æ®å¯¼å…¥å‡½æ•° ---
def import_students_to_db(db: Session, students_df: pd.DataFrame):
    """å°†å­¦ç”Ÿæ•°æ®ï¼ˆä»…æ•°æ®ï¼Œä¸ç”ŸæˆåµŒå…¥ï¼‰å¯¼å…¥æ•°æ®åº“ã€‚"""
    print("\nå¼€å§‹å¯¼å…¥å­¦ç”Ÿæ•°æ®åˆ°æ•°æ®åº“...")
    
    try:
        for i, row in students_df.iterrows():
            skills_data = row['skills']
            if isinstance(skills_data, str):
                try:
                    skills_data = json.loads(skills_data)
                except json.JSONDecodeError:
                    skills_data = []
            elif pd.isna(skills_data):
                skills_data = []

            student = User(
                id=int(row['id']),
                name=row['name'],
                major=row['major'],
                username=row['username'],
                skills=skills_data,
                interests=row['interests'],
                bio=row['bio'],
                awards_competitions=row['awards_competitions'],
                academic_achievements=row['academic_achievements'],
                soft_skills=row['soft_skills'],
                portfolio_link=row['portfolio_link'],
                preferred_role=row['preferred_role'],
                availability=row['availability'],
                location=row['location'] if pd.notna(row['location']) else None,
                email=row['email'],
                phone_number=row['phone_number'],
                school=row['school'],
                password_hash=row['password_hash'],
                combined_text=row['combined_text'],
                embedding=np.zeros(DEFAULT_EMBEDDING_DIM).tolist(),  # ä½¿ç”¨å¸¸é‡
                llm_api_type=None,
                llm_api_key_encrypted=None,
                llm_api_base_url=None,
                llm_model_id=None
            )

            db.add(student)
            print(f"æ·»åŠ å­¦ç”Ÿ: {student.name} (ç”¨æˆ·å: {student.username})")
        
        db.commit()
        print("å­¦ç”Ÿæ•°æ®å¯¼å…¥å®Œæˆã€‚")
        
    except Exception as e:
        db.rollback()
        print(f"å¯¼å…¥å­¦ç”Ÿæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise


def import_projects_to_db(db: Session, projects_df: pd.DataFrame):
    """å°†é¡¹ç›®æ•°æ®ï¼ˆä»…æ•°æ®ï¼Œä¸ç”ŸæˆåµŒå…¥ï¼‰å¯¼å…¥æ•°æ®åº“ã€‚"""
    print("\nå¼€å§‹å¯¼å…¥é¡¹ç›®æ•°æ®åˆ°æ•°æ®åº“...")
    
    # é¢„å…ˆè·å–æ‰€æœ‰å­¦ç”ŸIDï¼Œé¿å…é‡å¤æŸ¥è¯¢
    existing_student_ids = [s.id for s in db.query(User.id).all()]
    
    if not existing_student_ids:
        raise ValueError("æ— æ³•ä¸ºé¡¹ç›®åˆ†é…åˆ›å»ºè€…ï¼Œå› ä¸ºæ•°æ®åº“ä¸­æ²¡æœ‰å­¦ç”Ÿè®°å½•ã€‚è¯·å…ˆå¯¼å…¥å­¦ç”Ÿæ•°æ®ã€‚")
    
    try:
        for i, row in projects_df.iterrows():
            # å¤„ç†åˆ›å»ºè€…ID
            if pd.notna(row['creator_id']):
                creator_id_for_db = int(row['creator_id'])
            else:
                # éšæœºé€‰æ‹©ä¸€ä¸ªå·²å­˜åœ¨çš„å­¦ç”ŸID
                creator_id_for_db = np.random.choice(existing_student_ids)
                print(f"é¡¹ç›® {row['id']} æœªæŒ‡å®šåˆ›å»ºè€…ï¼Œéšæœºåˆ†é…åˆ›å»ºè€…ID: {creator_id_for_db}")

            # å¤„ç†æ—¥æœŸå­—æ®µ
            start_date_val = row['start_date'] if pd.notna(row['start_date']) else None
            end_date_val = row['end_date'] if pd.notna(row['end_date']) else None
            estimated_weekly_hours_val = row['estimated_weekly_hours'] if pd.notna(row['estimated_weekly_hours']) else None

            # å¤„ç†æŠ€èƒ½å’Œè§’è‰²æ•°æ®
            required_skills_data = parse_json_field(row['required_skills'], "required_skills", [])
            required_roles_data = parse_json_field(row['required_roles'], "required_roles", [])

            project = Project(
                id=int(row['id']),
                title=row['title'],
                description=row['description'],
                required_skills=required_skills_data,
                required_roles=required_roles_data,
                keywords=row['keywords'],
                project_type=row['project_type'],
                expected_deliverables=row['expected_deliverables'],
                contact_person_info=row['contact_person_info'],
                learning_outcomes=row['learning_outcomes'],
                team_size_preference=row['team_size_preference'],
                project_status=row['project_status'],
                start_date=start_date_val,
                end_date=end_date_val,
                estimated_weekly_hours=estimated_weekly_hours_val,
                location=row['location'] if pd.notna(row['location']) else None,
                creator_id=creator_id_for_db,
                combined_text=row['combined_text'],
                embedding=np.zeros(DEFAULT_EMBEDDING_DIM).tolist()  # ä½¿ç”¨å¸¸é‡
            )

            db.add(project)
            print(f"æ·»åŠ é¡¹ç›®: {project.title} (åˆ›å»ºè€…ID: {project.creator_id})")
        
        db.commit()
        print("é¡¹ç›®æ•°æ®å¯¼å…¥å®Œæˆã€‚")
        
    except Exception as e:
        db.rollback()
        print(f"å¯¼å…¥é¡¹ç›®æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise

# æ’å…¥é»˜è®¤æˆå°±çš„å‡½æ•°ï¼ˆå·²åºŸå¼ƒï¼Œæˆå°±åˆå§‹åŒ–å·²é›†æˆåˆ°database.pyä¸­ï¼‰
def insert_default_achievements(db: Session):
    """
    æ’å…¥é¢„è®¾çš„æˆå°±åˆ°æ•°æ®åº“ä¸­ï¼Œå¦‚æœåŒåæˆå°±å·²å­˜åœ¨åˆ™è·³è¿‡ã€‚
    æ³¨æ„ï¼šæ­¤å‡½æ•°å·²åºŸå¼ƒï¼Œæˆå°±åˆå§‹åŒ–ç°åœ¨ç”±database.pyçš„init_db()è‡ªåŠ¨å¤„ç†
    """
    print("\nâš ï¸  æ­¤å‡½æ•°å·²åºŸå¼ƒï¼šæˆå°±åˆå§‹åŒ–ç°åœ¨ç”±database.pyè‡ªåŠ¨å¤„ç†")
    print("æˆå°±ä¼šåœ¨æ•°æ®åº“è¡¨åˆ›å»ºåè‡ªåŠ¨åˆå§‹åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨æ­¤å‡½æ•°ã€‚")


# --- ä¸»æ‰§è¡Œæµç¨‹ ---
def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("--- å¼€å§‹æ•°æ®å¯¼å…¥æµç¨‹ ---")

    try:
        # 1. åˆå§‹åŒ–æ•°æ®åº“è¡¨ï¼ˆå¦‚æœå°šæœªåˆ›å»ºï¼‰
        init_db()

        # 2. ä»CSVåŠ è½½æ•°æ®
        print(f"æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶...")
        print(f"å­¦ç”Ÿæ•°æ®: {STUDENTS_CSV_PATH}")
        print(f"é¡¹ç›®æ•°æ®: {PROJECTS_CSV_PATH}")
        
        students_df = pd.read_csv(STUDENTS_CSV_PATH)
        projects_df = pd.read_csv(PROJECTS_CSV_PATH)
        print("\nCSVæ•°æ®åŠ è½½æˆåŠŸï¼")

        # ç¡®ä¿IDåˆ—æ˜¯æ•´æ•°ç±»å‹
        students_df['id'] = students_df['id'].astype(int)
        projects_df['id'] = projects_df['id'].astype(int)

        # å°†æ—¥æœŸæ—¶é—´åˆ—è½¬æ¢ä¸º datetime å¯¹è±¡
        for col in ['start_date', 'end_date']:
            if col in projects_df.columns:
                projects_df[col] = pd.to_datetime(projects_df[col], errors='coerce')

        # å°† 'location' åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œç¼ºå¤±å€¼è½¬æ¢ä¸ºNone
        for df, name in [(students_df, 'å­¦ç”Ÿ'), (projects_df, 'é¡¹ç›®')]:
            if 'location' in df.columns:
                df['location'] = df['location'].astype(str).replace('nan', None)

        # 3. é¢„å¤„ç†æ•°æ®
        print("\nå¼€å§‹é¢„å¤„ç†æ•°æ®...")
        students_df = preprocess_student_data(students_df)
        projects_df = preprocess_project_data(projects_df)
        print("æ•°æ®é¢„å¤„ç†å®Œæˆã€‚")

        # 4. è·å–æ•°æ®åº“ä¼šè¯å¹¶å¯¼å…¥æ•°æ®
        db_session = SessionLocal()
        try:
            import_students_to_db(db_session, students_df)
            import_projects_to_db(db_session, projects_df)
            
            print("\nâœ… æ‰€æœ‰æ•°æ®å¯¼å…¥æˆåŠŸï¼")
            print("ğŸ’¡ æ³¨æ„ï¼šé»˜è®¤æˆå°±å·²åœ¨æ•°æ®åº“åˆå§‹åŒ–æ—¶è‡ªåŠ¨åˆ›å»º")
        except Exception as e:
            db_session.rollback()
            print(f"\nâŒ æ•°æ®å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œäº‹åŠ¡å·²å›æ»š: {e}")
            import traceback
            traceback.print_exc()
            raise
        finally:
            db_session.close()

    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯ï¼šCSVæ–‡ä»¶æœªæ‰¾åˆ° - {e}")
        print(f"è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨ï¼š")
        print(f"  - {STUDENTS_CSV_PATH}")
        print(f"  - {PROJECTS_CSV_PATH}")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()
    
    print("\n--- æ•°æ®å¯¼å…¥æµç¨‹ç»“æŸ ---")


if __name__ == "__main__":
    main()
